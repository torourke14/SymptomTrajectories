{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiDi49JbAywy"
   },
   "source": [
    "**Config**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4271,
     "status": "ok",
     "timestamp": 1754902092526,
     "user": {
      "displayName": "Tanner O'Rourke",
      "userId": "10782217287266162712"
     },
     "user_tz": 420
    },
    "id": "VJ_a6e444iB7",
    "outputId": "0e66ed1f-bbe7-4378-c439-f1f2c1394396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "PARSED_DIR = '/content/drive/MyDrive/SymptomTrajectories/out-data'\n",
    "TRAIN_DIR   = '/content/drive/MyDrive/SymptomTrajectories/training-data'\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTGuhcriZuF8"
   },
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGRs9L6nZulG"
   },
   "outputs": [],
   "source": [
    "DX_ADHERENCE_THRESHOLD    = 0.8 # % adherence line to signal decreasing MH\n",
    "PHQ9_SPIKE_TRIGGER        = 5.0 # Numerical spike in phq 9 to signal decreasing MH\n",
    "UTILIZATION_SPIKE_TRIGGER = 2.0\n",
    "RELAPSE_HORIZON_DAYS      = 30\n",
    "\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT   = 0.10 # Clean slice for early stopping, debugging, etc\n",
    "TEST_SPLIT  = 0.15\n",
    "\n",
    "mental_health_regex     = r\"depress|anxiet|bipolar|schizo|psych|suicid|ptsd|panic|ocd|substance|addict\"\n",
    "severe_condition_regex  = r\"severe|psychosis|suicid|mania|catatonia|acute\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ee1IRiFRVmH"
   },
   "source": [
    "**Load Prepared Feature Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWuiHcSzRqpP"
   },
   "outputs": [],
   "source": [
    "patients = pd.read_csv(os.path.join(PARSED_DIR, \"patients.csv\"),\n",
    "  parse_dates=[\"birthdate\"],\n",
    "  usecols=[\"patient_id\", \"birthdate\", \"sex\", \"race\"],\n",
    "  low_memory=False,\n",
    "  compression=\"gzip\"\n",
    ")\n",
    "encounters = pd.read_csv(os.path.join(PARSED_DIR, \"encounters.csv\"),\n",
    "  parse_dates=[\"start_time\"],\n",
    "  usecols=[\"patient_id\", \"start_time\", \"enc_class_bucket\"],\n",
    "  low_memory=False,\n",
    "  compression=\"gzip\"\n",
    ")\n",
    "conditions = pd.read_csv(os.path.join(PARSED_DIR, \"conditions.csv\"),\n",
    "  parse_dates=[\"start_time\"],\n",
    "  usecols=[\"patient_id\", \"start_time\", \"snomed_code\", \"description\"],\n",
    "  low_memory=False,\n",
    "  compression=\"gzip\"\n",
    ")\n",
    "meds = pd.read_csv(os.path.join(PARSED_DIR, \"medications.csv\"),\n",
    "  parse_dates=[\"start_time\"],\n",
    "  usecols=[\"patient_id\", \"start_time\", \"rx_code\", \"description\"],\n",
    "  low_memory=False,\n",
    "  compression=\"gzip\"\n",
    ")\n",
    "observations = pd.read_csv(os.path.join(PARSED_DIR, \"observations.csv\"),\n",
    "  parse_dates=[\"obs_time\"],\n",
    "  usecols=[\"patient_id\", \"obs_time\", \"loinc_code\", \"description\", \"value\", \"units\"],\n",
    "  low_memory=False,\n",
    "  compression=\"gzip\"\n",
    ")\n",
    "daily = pd.read_csv(os.path.join(PARSED_DIR, \"daily.csv\"),\n",
    "  parse_dates=[\"date\"],\n",
    "  low_memory=False,\n",
    "  compression=\"gzip\"\n",
    ")\n",
    "events = pd.read_csv(os.path.join(PARSED_DIR, \"events.csv\"),\n",
    "  parse_dates=[\"date\"],\n",
    "  usecols=[\"patient_id\", \"date\", \"event_type\", \"code\"],\n",
    "  low_memory=False,\n",
    "  compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 94,
     "status": "error",
     "timestamp": 1754953018647,
     "user": {
      "displayName": "Tanner O'Rourke",
      "userId": "10782217287266162712"
     },
     "user_tz": 420
    },
    "id": "3mpNnz4VRqvE",
    "outputId": "e68070ba-fe5f-46b8-b761-aa874edeaf3b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3252841485.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m patients, encounters, conditions, meds, observations, daily, events = harmonize_types(\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpatients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencounters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconditions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patients' is not defined"
     ]
    }
   ],
   "source": [
    "# Helper to ensure no Errors when comparing dates w and w/o timezones\n",
    "def harmonize_types(patients, encounters, conditions, meds, observations, daily, events):\n",
    "  def _tz_naive(series):\n",
    "    if not np.issubdtype(series.dtype, np.datetime64):\n",
    "      series = pd.to_datetime(series, errors=\"coerce\", utc=False)\n",
    "    try:\n",
    "      return series.dt.tz_localize(None)\n",
    "    except AttributeError:\n",
    "        return series\n",
    "\n",
    "  daily[\"date\"]            = _tz_naive(daily[\"date\"])\n",
    "  events[\"date\"]           = _tz_naive(events[\"date\"])\n",
    "  encounters[\"start_time\"] = _tz_naive(encounters[\"start_time\"])\n",
    "  conditions[\"start_time\"] = _tz_naive(conditions[\"start_time\"])\n",
    "  # observations obs_time tz-naive (even though not used directly downstream)\n",
    "  if \"obs_time\" in observations.columns:\n",
    "    observations[\"obs_time\"] = _tz_naive(observations[\"obs_time\"])\n",
    "\n",
    "  events[\"event_type\"] = events[\"event_type\"].astype(str).str.lower().str.strip()\n",
    "  return patients, encounters, conditions, meds, observations, daily, events\n",
    "\n",
    "patients, encounters, conditions, meds, observations, daily, events = harmonize_types(\n",
    "    patients, encounters, conditions, meds, observations, daily, events\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vh6PBfiqbmV"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hG-xY_SFRgKF"
   },
   "source": [
    "# Factorize Events/Codes into UID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iljR2EtcT7_D"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Factorize (event_type|code) -> int ids; group per‑day grouping.\n",
    "Returns code ids per day, and list of all code id's for analysis\n",
    "\"\"\"\n",
    "def encode_codes_factorize(events):\n",
    "  keys = events[\"event_type\"] + \"|\" + events[\"code\"]\n",
    "  ids, uniques = pd.factorize(keys, sort=True)\n",
    "  ids = (ids.astype(np.int32) + 1) if ids.size else ids  # reserve 0 for padding tensor for if non-empty\n",
    "\n",
    "  # frequency for analysis\n",
    "  freq = pd.Series(keys).value_counts()\n",
    "  cookbook = (pd.DataFrame({\"key\": uniques})\n",
    "    .assign(id=lambda d: np.arange(1, len(d)+1, dtype=np.int32))\n",
    "    .assign(type=lambda d: d[\"key\"].str.split(\"|\", n=1).str[0],\n",
    "            code=lambda d: d[\"key\"].str.split(\"|\", n=1).str[1],\n",
    "            freq=lambda d: d[\"key\"].map(freq).fillna(0).astype(int))\n",
    "    [[\"id\", \"type\", \"code\", \"key\", \"freq\"]]\n",
    "  )\n",
    "\n",
    "  events = events.assign(code_id=ids) if ids.size else events.assign(code_id=np.array([], dtype=np.int32))\n",
    "\n",
    "  def _uniq_json(s):\n",
    "    return json.dumps(sorted(set(map(int, s.tolist()))))\n",
    "\n",
    "  per_day = (events\n",
    "    .groupby([\"patient_id\", \"date\"], observed=True)[\"code_id\"]\n",
    "      .apply(_uniq_json)\n",
    "      .reset_index()\n",
    "      .rename(columns={\"code_id\": \"code_ids\"})\n",
    "      if len(events) else pd.DataFrame(columns=[\"patient_id\",\"date\",\"code_ids\"])\n",
    "  )\n",
    "  return per_day, cookbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jg-GunCNOqco"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recompute labels\n",
    "- y_relapse: future <= 30days: (ED/INPATIENT & MH condition same day) OR severe condition OR ad_gap_days >= 30\n",
    "- y_det: future <= 30d: PHQ9 rises >= FLAG OR util_7d rises by >= FLAG OR medication starts (ad_covered 0->1)\n",
    "- non_adherent_flag: pdc < FLAG OR ad_gap_days >= 1\n",
    "\"\"\"\n",
    "def compute_labels(daily, encounters, conditions):\n",
    "  daily_df = daily.copy()\n",
    "\n",
    "  # Day‑granularity views for encounters/conditions\n",
    "  encounter_days_df  = encounters.assign(date=encounters[\"start_time\"].dt.floor(\"D\"))[ [\"patient_id\",\"date\",\"enc_class_bucket\"] ]\n",
    "  condition_days_df  = conditions.assign(date=conditions[\"start_time\"].dt.floor(\"D\"))[ [\"patient_id\",\"date\",\"description\"] ]\n",
    "\n",
    "  # --- Adherence label\n",
    "  pdc_col = next(c for c in daily_df.columns if c.startswith(\"pdc_\"))  # Step 2 guarantees one pdc_* column\n",
    "  daily_df[\"non_adherent_flag\"] = (\n",
    "      (daily_df[\"ad_gap_days\"].fillna(0).astype(float) >= 1) |\n",
    "      (daily_df[pdc_col].fillna(0).astype(float) < 0.8)\n",
    "  ).astype(\"int8\")\n",
    "\n",
    "  # --- Relapse anchors\n",
    "  mental_health_regex     = r\"depress|anxiet|bipolar|schizo|psych|suicid|ptsd|panic|ocd|substance|addict\"\n",
    "  severe_condition_regex  = r\"severe|psychosis|suicid|mania|catatonia|acute\"\n",
    "\n",
    "  mh_conditions      = condition_days_df.loc[\n",
    "      condition_days_df[\"description\"].str.contains(mental_health_regex, case=False, na=False),\n",
    "      [\"patient_id\",\"date\"]\n",
    "  ]\n",
    "  severe_conditions  = condition_days_df.loc[\n",
    "      condition_days_df[\"description\"].str.contains(severe_condition_regex, case=False, na=False),\n",
    "      [\"patient_id\",\"date\"]\n",
    "  ]\n",
    "  acute_encounters   = encounter_days_df.loc[\n",
    "      encounter_days_df[\"enc_class_bucket\"].str.upper().isin([\"EMERGENCY\",\"INPATIENT\"]),\n",
    "      [\"patient_id\",\"date\"]\n",
    "  ]\n",
    "\n",
    "  ed_with_mh_same_day   = mh_conditions.merge(acute_encounters, on=[\"patient_id\",\"date\"], how=\"inner\").drop_duplicates()\n",
    "  long_medication_gap   = daily_df.loc[daily_df[\"ad_gap_days\"].fillna(0).astype(float) >= 30, [\"patient_id\",\"date\"]]\n",
    "  relapse_anchor_dates  = pd.concat([ed_with_mh_same_day, severe_conditions, long_medication_gap], ignore_index=True).drop_duplicates()\n",
    "\n",
    "  # --- y_relapse: whether a relapse anchor occurs within 30 days after each day\n",
    "  daily_df[\"y_relapse\"] = 0\n",
    "  for patient_id, patient_days in daily_df.groupby(\"patient_id\", sort=False):\n",
    "      row_index   = patient_days.index\n",
    "      day_dates   = patient_days[\"date\"].to_numpy(dtype=\"datetime64[D]\")\n",
    "      anchor_dates= relapse_anchor_dates.loc[\n",
    "          relapse_anchor_dates[\"patient_id\"] == patient_id, \"date\"\n",
    "      ].to_numpy(dtype=\"datetime64[D]\")\n",
    "      anchor_dates = np.sort(anchor_dates)\n",
    "\n",
    "      next_anchor_idx     = np.searchsorted(anchor_dates, day_dates + np.timedelta64(1, 'D'), side='left')\n",
    "      has_future_anchor   = (next_anchor_idx < anchor_dates.size)\n",
    "      within_30d          = np.zeros_like(has_future_anchor, dtype=bool)\n",
    "      valid_rows          = np.where(has_future_anchor)[0]\n",
    "      if valid_rows.size:\n",
    "        deltas = anchor_dates[next_anchor_idx[valid_rows]] - day_dates[valid_rows]\n",
    "        within_30d[valid_rows] = deltas <= np.timedelta64(30, 'D')\n",
    "      daily_df.loc[row_index, \"y_relapse\"] = (has_future_anchor & within_30d).astype(\"int8\")\n",
    "\n",
    "  # --- y_det: subtle deterioration within the next 30 days\n",
    "  daily_df[\"y_det\"] = 0\n",
    "  for patient_id, patient_days in daily_df.groupby(\"patient_id\", sort=False):\n",
    "      row_index        = patient_days.index\n",
    "      day_dates        = patient_days[\"date\"].to_numpy(dtype=\"datetime64[D]\")\n",
    "      phq9_values      = patient_days.get(\"phq9\", pd.Series(index=row_index, dtype=float)).to_numpy(dtype=float)\n",
    "      util7_values     = patient_days.get(\"util_7d\", pd.Series(index=row_index, dtype=float)).to_numpy(dtype=float)\n",
    "      adherence_values = patient_days.get(\"ad_covered\", pd.Series(index=row_index, dtype=float)).to_numpy(dtype=float)\n",
    "\n",
    "      n_days                 = len(patient_days)\n",
    "      future_phq9_max        = np.full(n_days, np.nan, dtype=float)\n",
    "      future_util7_max       = np.zeros(n_days, dtype=float)\n",
    "      future_any_med_covered = np.zeros(n_days, dtype=bool)\n",
    "\n",
    "      for i in range(n_days):\n",
    "          in_horizon = (day_dates > day_dates[i]) & (day_dates <= day_dates[i] + np.timedelta64(30, 'D'))\n",
    "          idx_future = np.where(in_horizon)[0]\n",
    "          if idx_future.size:\n",
    "              future_phq_vals   = phq9_values[idx_future]\n",
    "              future_phq9_max[i]= np.nanmax(future_phq_vals) if np.isfinite(future_phq_vals).any() else np.nan\n",
    "              future_util7_max[i]= util7_values[idx_future].max()\n",
    "              future_any_med_covered[i] = (adherence_values[idx_future] == 1).any()\n",
    "\n",
    "      future_phq9_rise   = (~np.isnan(future_phq9_max)) & (~np.isnan(phq9_values)) & ((future_phq9_max - phq9_values) >= 5.0)\n",
    "      utilization_spike  = (future_util7_max - util7_values) >= 2.0\n",
    "      medication_start   = (adherence_values == 0) & future_any_med_covered\n",
    "      deterioration_flag = future_phq9_rise | utilization_spike | medication_start\n",
    "      daily_df.loc[row_index, \"y_det\"] = deterioration_flag.astype(\"int8\")\n",
    "\n",
    "  return daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d48Xr-TRRgkc"
   },
   "source": [
    "## Generate Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QV5koOYMAyL6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Do a stratified random sample of the population by\n",
    "- stratifying into pos (y_relapse=1) and neg groups -> sampling -> merging\n",
    "- Check each patient for for > 1 eventful day\n",
    "\"\"\"\n",
    "\n",
    "# Split by patient!! Models are smart\n",
    "def build_splits(model_table, seed=42):\n",
    "  cols = [\"y_relapse\", \"y_det\"]\n",
    "  rng = np.random.default_rng(seed)\n",
    "\n",
    "  per_patient_max = model_table.groupby(\"patient_id\")[cols].max(min_count=1).fillna(0)\n",
    "  has_pos = (per_patient_max.max(axis=1) >= 1).to_numpy()\n",
    "\n",
    "  pos_pids = per_patient_max.index[has_pos].to_numpy()\n",
    "  neg_pids = per_patient_max.index[~has_pos].to_numpy()\n",
    "  rng.shuffle(pos_pids)\n",
    "  rng.shuffle(neg_pids)\n",
    "\n",
    "  def _split_group(arr):\n",
    "    n = len(arr)\n",
    "    n_tr = int(round(n * TRAIN_SPLIT))\n",
    "    n_val = int(round(n * VAL_SPLIT))\n",
    "    if n_tr + n_val > n:\n",
    "        n_val = max(0, n - n_tr)\n",
    "    n_te = max(0, n - n_tr - n_val)\n",
    "    return arr[:n_tr], arr[n_tr:n_tr+n_val], arr[n_tr+n_val:]\n",
    "\n",
    "  pos_tr, pos_val, pos_te = _split_group(pos_pids)\n",
    "  neg_tr, neg_val, neg_te = _split_group(neg_pids)\n",
    "\n",
    "  # Merge groups, re-randomize, split\n",
    "  train_ids = np.array(list(pos_tr) + list(neg_tr))\n",
    "  val_ids   = np.array(list(pos_val) + list(neg_val))\n",
    "  test_ids  = np.array(list(pos_te) + list(neg_te))\n",
    "  rng.shuffle(train_ids)\n",
    "  rng.shuffle(val_ids)\n",
    "  rng.shuffle(test_ids)\n",
    "  split = (\n",
    "    [(pid, \"train\") for pid in train_ids] +\n",
    "    [(pid, \"val\")   for pid in val_ids] +\n",
    "    [(pid, \"test\")  for pid in test_ids]\n",
    "  )\n",
    "  return pd.DataFrame(split, columns=[\"patient_id\",\"split\"])\n",
    "\n",
    "\"\"\"\n",
    "Return per-label positive weight = num neg / num pos\n",
    "\"Scalar\": y_relapse, y_det, non_adherent_flag\n",
    "\"cb\": comorbidity blindspots\n",
    "\"\"\"\n",
    "def compute_pos_weights(model_table):\n",
    "  def _pos_weight(series):\n",
    "    counts = series.astype(\"float32\").value_counts()\n",
    "    pos = int(counts.get(1.0, 0))\n",
    "    neg = int(counts.get(0.0, 0))\n",
    "    return float(neg / pos) if pos > 0 and neg > 0 else None\n",
    "\n",
    "  scalar_cols = [c for c in [\"y_relapse\", \"y_det\", \"non_adherent_flag\"] if c in model_table.columns]\n",
    "  scalar = { c: _pos_weight(model_table[c]) for c in scalar_cols }\n",
    "  scalar = { k: v for k, v in scalar.items() if v is not None }\n",
    "\n",
    "  cb_cols = [c for c in model_table.columns if c.startswith(\"cb_\")]\n",
    "  cb = { c: _pos_weight(model_table[c]) for c in cb_cols }\n",
    "  cb = { k: v for k, v in cb.items() if v is not None }\n",
    "\n",
    "  return { \"scalar\": scalar, \"cb\": cb }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Joxy5v6NR0ue"
   },
   "source": [
    "## Prepare (Run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8D_xDuMeRz_B"
   },
   "outputs": [],
   "source": [
    "def build_training():\n",
    "  # factorize codes and build per‑day id bags\n",
    "  per_day_codes, cookbook = encode_codes_factorize(events);\n",
    "  daily_labeled = compute_labels(daily, encounters, conditions)\n",
    "\n",
    "  # merge to final train table\n",
    "  model_table = daily_labeled.merge(per_day_codes, how=\"left\", on=[\"patient_id\", \"date\"])\n",
    "  model_table[\"code_ids\"] = model_table[\"code_ids\"].fillna(\"[]\")\n",
    "  model_table.sort_values([\"patient_id\",\"date\"], inplace=True)\n",
    "\n",
    "  num_cols = model_table.select_dtypes(include=[\"number\",\"bool\"]).columns\n",
    "  model_table[num_cols] = model_table[num_cols].fillna(0)\n",
    "  print(\"Generated final model table\")\n",
    "\n",
    "  # splits + class imbalance weights\n",
    "  splits = build_splits(model_table)\n",
    "  posw   = compute_pos_weights(model_table)\n",
    "\n",
    "  return model_table, splits, posw, cookbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32931,
     "status": "ok",
     "timestamp": 1754902146620,
     "user": {
      "displayName": "Tanner O'Rourke",
      "userId": "10782217287266162712"
     },
     "user_tz": 420
    },
    "id": "a3Efm7t4cvFg",
    "outputId": "9ce764c3-ba09-4d28-9705-f63ba4e008e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated final model table\n"
     ]
    }
   ],
   "source": [
    "model_table, splits, posw, cookbook = build_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8mBXVy4pyRQ"
   },
   "outputs": [],
   "source": [
    "for col_name in model_table.columns:\n",
    "  if model_table[col_name].isnull().values.any():\n",
    "    print(model_table[col_name].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1754902166556,
     "user": {
      "displayName": "Tanner O'Rourke",
      "userId": "10782217287266162712"
     },
     "user_tz": 420
    },
    "id": "tV27TCr9o0_e",
    "outputId": "a4146f44-4e88-468c-e784-9e4b53fefc34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 732544 | Patients: 5736 | Vocab ids: 634\n",
      "Targets present: ['y_relapse', 'y_det', 'non_adherent_flag']\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows:\", len(model_table), \"| Patients:\", model_table[\"patient_id\"].nunique(), \"| Vocab ids:\", len(cookbook))\n",
    "print(\"Targets present:\", [c for c in [\"y_relapse\",\"y_det\",\"non_adherent_flag\"] if c in model_table.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3B1081dgoymN"
   },
   "outputs": [],
   "source": [
    "cookbook.to_csv(os.path.join(TRAIN_DIR, \"dx_uniques.csv\"), index=False)\n",
    "model_table.to_csv(os.path.join(TRAIN_DIR, \"model_table.csv\"), index=False)\n",
    "splits.to_csv(os.path.join(TRAIN_DIR, \"splits.csv\"), index=False)\n",
    "with open(os.path.join(TRAIN_DIR, \"pos_weights.json\"), \"w\") as f:\n",
    "  json.dump(posw, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jImSECj8UaeS"
   },
   "source": [
    "**Reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1754902186133,
     "user": {
      "displayName": "Tanner O'Rourke",
      "userId": "10782217287266162712"
     },
     "user_tz": 420
    },
    "id": "81YTpZ1hnJBx",
    "outputId": "1c66524b-9759-46db-848f-1a322b2e6cd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'patient_id', 'date', 'age_years', 'EMERGENCY', 'INPATIENT',\n",
      "       'OTHER', 'OUTPATIENT', 'URGENTCARE', 'WELLNESS', 'util_7d', 'phq9',\n",
      "       'phq2', 'gad7', 'auditc', 'dast10', 'pregnancy_pos', 'ad_covered',\n",
      "       'pdc_90', 'ad_gap_days', 'days_since_prev', 'sex_M', 'sex_F',\n",
      "       'race_white', 'race_black', 'race_asian', 'race_hawaiian', 'race_other',\n",
      "       'race_native', 'non_adherent_flag', 'y_relapse', 'y_det', 'code_ids'],\n",
      "      dtype='object')\n",
      "    index                            patient_id       date  age_years  \\\n",
      "0   22109  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-02-27         75   \n",
      "1   22110  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-02-28         75   \n",
      "2   22111  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-01         75   \n",
      "3   22112  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-02         75   \n",
      "4   22113  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-03         75   \n",
      "5   22114  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-04         75   \n",
      "6   22115  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-05         75   \n",
      "7   22116  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-06         75   \n",
      "8   22117  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-07         75   \n",
      "9   22118  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-08         75   \n",
      "10  22119  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-09         75   \n",
      "11  22120  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-10         75   \n",
      "12  22121  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-11         75   \n",
      "13  22122  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-12         75   \n",
      "14  22123  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-13         75   \n",
      "15  22124  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-14         75   \n",
      "16  22125  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-15         75   \n",
      "17  22126  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-16         75   \n",
      "18  22127  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-17         75   \n",
      "19  22128  0002a287-8563-a8c2-4a4e-bea0aa749024 2025-03-18         75   \n",
      "\n",
      "    EMERGENCY  INPATIENT  OTHER  OUTPATIENT  URGENTCARE  WELLNESS  ...  \\\n",
      "0           0          0      0           0           0         0  ...   \n",
      "1           0          0      0           0           0         0  ...   \n",
      "2           0          0      0           0           0         0  ...   \n",
      "3           0          0      0           0           0         0  ...   \n",
      "4           0          0      0           0           0         0  ...   \n",
      "5           0          0      0           0           0         0  ...   \n",
      "6           0          0      0           0           0         0  ...   \n",
      "7           0          0      0           0           0         0  ...   \n",
      "8           0          0      0           0           0         0  ...   \n",
      "9           0          0      0           0           0         0  ...   \n",
      "10          0          0      0           0           0         0  ...   \n",
      "11          0          0      0           0           0         0  ...   \n",
      "12          0          0      0           0           0         0  ...   \n",
      "13          0          0      0           0           0         0  ...   \n",
      "14          0          0      0           0           0         0  ...   \n",
      "15          0          0      0           0           0         0  ...   \n",
      "16          0          0      0           0           0         0  ...   \n",
      "17          0          0      0           0           0         0  ...   \n",
      "18          0          0      0           0           0         0  ...   \n",
      "19          0          0      0           0           0         0  ...   \n",
      "\n",
      "    race_white  race_black  race_asian  race_hawaiian  race_other  \\\n",
      "0            1           0           0              0           0   \n",
      "1            1           0           0              0           0   \n",
      "2            1           0           0              0           0   \n",
      "3            1           0           0              0           0   \n",
      "4            1           0           0              0           0   \n",
      "5            1           0           0              0           0   \n",
      "6            1           0           0              0           0   \n",
      "7            1           0           0              0           0   \n",
      "8            1           0           0              0           0   \n",
      "9            1           0           0              0           0   \n",
      "10           1           0           0              0           0   \n",
      "11           1           0           0              0           0   \n",
      "12           1           0           0              0           0   \n",
      "13           1           0           0              0           0   \n",
      "14           1           0           0              0           0   \n",
      "15           1           0           0              0           0   \n",
      "16           1           0           0              0           0   \n",
      "17           1           0           0              0           0   \n",
      "18           1           0           0              0           0   \n",
      "19           1           0           0              0           0   \n",
      "\n",
      "    race_native  non_adherent_flag  y_relapse  y_det  code_ids  \n",
      "0             0                  1          0      0        []  \n",
      "1             0                  1          0      0        []  \n",
      "2             0                  1          0      0        []  \n",
      "3             0                  1          0      0        []  \n",
      "4             0                  1          0      0        []  \n",
      "5             0                  1          0      0        []  \n",
      "6             0                  1          0      0        []  \n",
      "7             0                  1          0      0        []  \n",
      "8             0                  1          0      0        []  \n",
      "9             0                  1          0      0        []  \n",
      "10            0                  1          0      0        []  \n",
      "11            0                  1          0      0        []  \n",
      "12            0                  1          0      0        []  \n",
      "13            0                  1          0      0        []  \n",
      "14            0                  1          0      0        []  \n",
      "15            0                  1          0      0        []  \n",
      "16            0                  1          0      0        []  \n",
      "17            0                  1          0      0        []  \n",
      "18            0                  1          0      0        []  \n",
      "19            0                  1          0      0        []  \n",
      "\n",
      "[20 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(model_table.columns)\n",
    "print(model_table.head(20))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMgBMOaAO8gJb5zAEvE+Qh3",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
